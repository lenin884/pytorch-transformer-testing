{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed41e4bd",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Neural-Machine-Translation-Seq2Seq\" data-toc-modified-id=\"Neural-Machine-Translation-Seq2Seq-1\">Neural Machine Translation Seq2Seq</a></span><ul class=\"toc-item\"><li><span><a href=\"#Download-dataset\" data-toc-modified-id=\"Download-dataset-1.1\">Download dataset</a></span></li><li><span><a href=\"#Preparing-data\" data-toc-modified-id=\"Preparing-data-1.2\">Preparing data</a></span></li><li><span><a href=\"#Encoder\" data-toc-modified-id=\"Encoder-1.3\">Encoder</a></span></li><li><span><a href=\"#Decoder\" data-toc-modified-id=\"Decoder-1.4\">Decoder</a></span></li><li><span><a href=\"#Seq2Seq\" data-toc-modified-id=\"Seq2Seq-1.5\">Seq2Seq</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-1.6\">Training</a></span></li><li><span><a href=\"#Generate-Text\" data-toc-modified-id=\"Generate-Text-1.7\">Generate Text</a></span></li><li><span><a href=\"#BLEU-metrics\" data-toc-modified-id=\"BLEU-metrics-1.8\">BLEU metrics</a></span></li><li><span><a href=\"#Writer-to-tensorboard-logs\" data-toc-modified-id=\"Writer-to-tensorboard-logs-1.9\">Writer to tensorboard logs</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d15f0",
   "metadata": {},
   "source": [
    "# Neural Machine Translation Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e17a1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: runs: File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab36c89",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f234d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-31 17:34:25--  https://github.com/yandexdataschool/nlp_course/raw/2020/week04_seq2seq/data.txt\n",
      "Распознаётся github.com (github.com)… 140.82.121.4\n",
      "Подключение к github.com (github.com)|140.82.121.4|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://raw.githubusercontent.com/yandexdataschool/nlp_course/2020/week04_seq2seq/data.txt [переход]\n",
      "--2021-07-31 17:34:25--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/2020/week04_seq2seq/data.txt\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 12905335 (12M) [text/plain]\n",
      "Сохранение в: «data.txt»\n",
      "\n",
      "data.txt            100%[===================>]  12,31M  7,00MB/s    за 1,8s    \n",
      "\n",
      "2021-07-31 17:34:28 (7,00 MB/s) - «data.txt» сохранён [12905335/12905335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/yandexdataschool/nlp_course/raw/2020/week04_seq2seq/data.txt -O data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a046d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629bb05",
   "metadata": {},
   "source": [
    "We'll set the random seeds for deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75af238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7fde2",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "Here comes the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9b4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "\n",
    "def tokenize_ru(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())[::-1]\n",
    "\n",
    "def tokenize_en(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2d0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_ru,\n",
    "           init_token=\"<sos>\",\n",
    "           eos_token=\"<eos>\",\n",
    "           lower=True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize_en,\n",
    "           init_token=\"<sos>\",\n",
    "           eos_token=\"<eos>\",\n",
    "           lower=True)\n",
    "\n",
    "dataset = torchtext.legacy.data.TabularDataset(\n",
    "    path=\"data.txt\",\n",
    "    format=\"tsv\",\n",
    "    fields=[(\"trg\", TRG), (\"src\", SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3dec04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 39992\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7498\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c74ebe",
   "metadata": {},
   "source": [
    "Setup vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e24d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8b864e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 14157\n",
      "Unique tokens in target (en) vocabulary: 10158\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067e676",
   "metadata": {},
   "source": [
    "And here is example from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ea2f273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['each', 'bathroom', 'is', 'fitted', 'with', 'a', 'hairdryer', 'and', 'free', 'toiletries', '.'], 'src': ['.', 'принадлежностями', 'косметическими', '-', 'туалетно', 'бесплатными', 'и', 'феном', 'с', 'комната', 'ванная', 'удобств', 'числе', 'в']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d734f",
   "metadata": {},
   "source": [
    "Setup torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b854b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb0bedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b260ab1",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eacc08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src = [src sent len, batch size]\n",
    "        \n",
    "        # Compute an embedding from the src data and apply dropout to it\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        # embedded = [src sent len, batch size, emb dim]\n",
    "        \n",
    "        # Compute the RNN output values of the encoder RNN\n",
    "        # outputs, hidden and cell shoud be initialized here. Refer to nn.LSTM docs :)\n",
    "        \n",
    "        _, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        # outputs = [src sent len, batch size, hid dim * n_directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        # outputs are always from the top hidden layer\n",
    "        if self.bidirectional:\n",
    "            hidden = hidden.reshape(self.n_layers, 2, -1, self.hid_dim)\n",
    "            hidden = hidden.transpose(1, 2).reshape(self.n_layers, -1, 2 * self.hid_dim)\n",
    "            \n",
    "            cell = cell.reshape(self.n_layers, 2, -1, self.hid_dim)\n",
    "            cell = cell.transpose(1, 2).reshape(self.n_layers, -1, 2 * self.hid_dim)\n",
    "        \n",
    "        return hidden, cell         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085ec27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a0c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b5968e7",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d0c456c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n leayers, batch size, hid dim]\n",
    "        #context = [n layers, batch, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        #Compute an embedding from the input data and apply dropout to it\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        # Compute the RNN output values of the encoder RNN.\n",
    "        # outputs, hidden and cell should be initialized here. Refer to nn.LSTM docs :)\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #sent len and n directions will always be 1 in the decoder, therefore\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef558e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82feb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582cafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "231d2851",
   "metadata": {},
   "source": [
    "## Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8144e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        if encoder.bidirectional:\n",
    "            assert encoder.hid_dim * 2 == decoder.hid_dim, \\\n",
    "                \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        else:\n",
    "            assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "                    \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc235fd",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "80e97c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reloading. Use Attention in Seq2Seq as homework\n",
    "# import modules\n",
    "# import imp\n",
    "# imp.reload(modules)\n",
    "\n",
    "# Encoder = modules.Encoder\n",
    "# Attention = modules.Attention\n",
    "# Decoder = modules.DecoderWithAttention\n",
    "# Seq2Seq = modules.Seq2Seq\n",
    "\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM // 2, N_LAYERS, ENC_DROPOUT, BIDIRECTIONAL)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "#Dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7e392811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(14157, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10158, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=10158, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d59b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 17,743,534 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "727c623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi[\"<pad>\"]\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, OUTPUT_DIM)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10 == 0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "            \n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label=\"train loss\")\n",
    "            ax[0].set_xlabel(\"Batch\")\n",
    "            ax[0].set_title(\"Train loss\")\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label=\"general train history\")\n",
    "                ax[1].set_xlabel(\"Epoch\")\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label=\"general valid history\")\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            output = model(src, trg, 0)\n",
    "            \n",
    "            output = output[1:].view(-1, OUTPUT_DIM)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins*60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef2e7728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/33/v262xgpj1zdf9ky3dnwngzqr0000gn/T/ipykernel_4680/4122471545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/33/v262xgpj1zdf9ky3dnwngzqr0000gn/T/ipykernel_4680/3081405210.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, train_history, valid_history)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Let's clip the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 12\n",
    "CLIP = 5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss;\n",
    "        torch.save(model.state_dict(), \"best-val-model.pt\")\n",
    "        \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:.3f} | Train PPL: {math.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd67287",
   "metadata": {},
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "093dc2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_on_eos(tokens_iter):\n",
    "    for token in tkens_iter:\n",
    "        if token == \"<eos>\":\n",
    "            break\n",
    "        yield token\n",
    "        \n",
    "def remove_tech_tokens(tokens_iter, tokens_to_remove=[\"<eos>\", \"<sos>\", \"<unk>\", \"<pad>\"]):\n",
    "    return [x for x in tokens_iter if x not in tokens_to_remove]\n",
    "\n",
    "def generate_translation(src, trg, model, TRG_vocab):\n",
    "    model.eval()\n",
    "    \n",
    "    output = model(src, trg, 0)\n",
    "    output = output[1:].argmax(-1)\n",
    "    \n",
    "    original = remove_tech_tokens(cut_on_eos([TRG_vocab.itos[x] for x in list(trg[:,0].cpu().numpy())]))\n",
    "    generated = remove_tech_tokens(cut_on_eos([TRG_vocab.itos[x] for x in list(output[:, 0]).cpu().numpy()]))\n",
    "    \n",
    "    print(\"Original: {}\".format(\" \".join(original)))\n",
    "    print(\"Generated: {}\".format(\" \".join(generated)))\n",
    "    print()\n",
    "    \n",
    "def get_text(x, TRG_vocab):\n",
    "    generated = remove_tech_tokens(cut_on_eos([TRG_vocab.itos[elem] for elem in list(x)]))\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "663509a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best-val-model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/33/v262xgpj1zdf9ky3dnwngzqr0000gn/T/ipykernel_4680/2135898501.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best-val-model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best-val-model.pt'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best-val-model.pt\"))\n",
    "batch = next(iter(test_iterator))\n",
    "\n",
    "for idx in range(10):\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d66bc9",
   "metadata": {},
   "source": [
    "## BLEU metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef065551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "        \n",
    "        output = output[1:].argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg[1:].cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output.detach().cpu().numpy().T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f1b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845970ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbaa09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89305ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58353487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1c1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6a76d76",
   "metadata": {},
   "source": [
    "## Writer to tensorboard logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6786a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# writer = SummaryWriter('runs/seq2seq_without_attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f96b4b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 128]) torch.Size([7, 128])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/33/v262xgpj1zdf9ky3dnwngzqr0000gn/T/ipykernel_4680/2816187360.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# writer.add_image('seq2seq', img_grid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         return trace_module(\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             module._c._create_method_from_trace(\n\u001b[0m\u001b[1;32m    953\u001b[0m                 \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/33/v262xgpj1zdf9ky3dnwngzqr0000gn/T/ipykernel_4680/2439055433.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m#insert input token embedding, previous hidden and previous cell states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m#receive output tensor (predictions) and new hidden and cell states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;31m#place predictions in a tensor holding predictions for each token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/33/v262xgpj1zdf9ky3dnwngzqr0000gn/T/ipykernel_4680/3860221751.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#Compute an embedding from the input data and apply dropout to it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#embedded = [1, batch size, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/Volumes/TOSHIBA/Pycharm/PytorchTransformers/venv/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# # Writing To TensorBoard\n",
    "# # get some random training images\n",
    "dataiter = iter(test_iterator)\n",
    "i, batch = next(dataiter)\n",
    "print(i[0].shape, i[1].shape)\n",
    "\n",
    "# # # create grid of images\n",
    "# img_grid = torchvision.utils.make_grid(i[0])\n",
    "\n",
    "# # # write to tensorboard\n",
    "# writer.add_image('seq2seq', img_grid)\n",
    "    \n",
    "writer.add_graph(model, (i[0], i[1]))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60532178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
